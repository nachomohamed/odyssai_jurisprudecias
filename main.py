# app.py
import json
import uuid
import pandas as pd
import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# =============================
# Configuraci√≥n base
# =============================
st.set_page_config(page_title="‚öñÔ∏è Jurisprudencia Assistant", layout="wide")
st.title("‚öñÔ∏è Jurisprudencia Assistant")

openai_api_key = st.secrets["OPENAI_KEY"]

# =============================
# Carga del retriever (MMR, k=10)
# =============================
@st.cache_resource
def load_retriever():
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        openai_api_key=openai_api_key
    )
    vs = FAISS.load_local(
        "vectorstore_jurisprudencia",
        embeddings,
        allow_dangerous_deserialization=True
    )
    retriever = vs.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 10,
            "fetch_k": 50,
            "lambda_mult": 0.5
        }
    )
    return retriever

retriever = load_retriever()
llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)

# =============================
# Helpers UI
# =============================
DISPLAY_ORDER = [
    "caratula",
    "tribunal_principal", "tribunal_sala",
    "tipo_causa",
    "nro_expediente", "nro_sentencia", "registro",
    "fecha_sentencia",
    "sumario",
    "texto",
]

def render_kv_table(meta: dict):
    meta = meta or {}
    rows, seen = [], set()
    for k in DISPLAY_ORDER:
        if k in meta and meta[k] not in (None, "", "nan"):
            if k in ["sumario", "texto"]:
                continue
            rows.append({"Columna": k, "Contenido": str(meta[k])})
            seen.add(k)
    for k, v in meta.items():
        if k in seen or k in ["sumario", "texto"]:
            continue
        if v not in (None, "", "nan"):
            rows.append({"Columna": k, "Contenido": str(v)})
    if rows:
        st.table(pd.DataFrame(rows))
    if meta.get("sumario"):
        with st.expander("sumario", expanded=True):
            st.write(str(meta["sumario"]))
    if meta.get("texto"):
        with st.expander("texto", expanded=False):
            st.write(str(meta["texto"]))

# =============================
# LLM: elegir 3 y explicar con bullets
# =============================
def llm_pick_top3_and_explain(user_query: str, candidates: list[dict]):
    """
    candidates: [{uid, descriptor, extracto}]
    Devuelve (intro:str, items:list[{uid, bullets, resumen}])
    """
    system = (
        "Eres un asistente jur√≠dico. Recibir√°s hasta 10 fallos candidatos. "
        "Debes elegir EXACTAMENTE 3. "
        "Para cada uno: explica con detalle en vi√±etas por qu√© es relevante. "
        "Incluye hechos clave, art√≠culo/norma (ej. art. 242 LCT si aparece), "
        "jurisdicci√≥n/instancia/fecha, y resultado/criterio. "
        "A√±ade al menos una cita breve entre comillas (‚â§12 palabras) del extracto. "
        "S√© claro y evita frases gen√©ricas."
    )
    user = (
        f"Consulta del abogado:\n{user_query}\n\n"
        "Fallos candidatos (uid, descriptor, extracto parcial):\n"
        f"{json.dumps(candidates, ensure_ascii=False)}\n\n"
        "TAREA:\n"
        "1) Selecciona los 3 fallos m√°s relevantes.\n"
        "2) Para cada uno devuelve vi√±etas ('‚Ä¢ ...') con explicaciones concretas (m√≠nimo 3 bullets). "
        "   Cierra con una frase-s√≠ntesis de por qu√© es el m√°s adecuado.\n"
        "3) Devuelve SOLO JSON con este formato:\n"
        "{\n"
        '  "intro": "texto de introducci√≥n",\n'
        '  "items": [\n'
        '    {"uid": "uid1", "bullets": ["‚Ä¢ punto 1", "‚Ä¢ punto 2", "‚Ä¢ punto 3"], "resumen": "frase final"},\n'
        '    {"uid": "uid2", "bullets": [...], "resumen": "..."},\n'
        '    {"uid": "uid3", "bullets": [...], "resumen": "..."}\n'
        "  ]\n"
        "}"
    )

    out = llm.invoke([
        {"role": "system", "content": system},
        {"role": "user", "content": user}
    ])
    text = out.content if hasattr(out, "content") else str(out)

    try:
        data = json.loads(text)
        intro = (data.get("intro") or "").strip()
        items = data.get("items") or []
        result = []
        for it in items[:3]:
            uid = (it.get("uid") or "").strip()
            bullets = it.get("bullets") or []
            resumen = (it.get("resumen") or "").strip()
            if uid and bullets and resumen:
                result.append({"uid": uid, "bullets": bullets, "resumen": resumen})
        if not result:
            raise ValueError("Modelo devolvi√≥ vac√≠o")
        return intro, result
    except Exception:
        intro = "Tras revisar tu consulta, seleccion√© los 3 fallos m√°s cercanos por hechos y normativa."
        result = [{"uid": c["uid"],
                   "bullets": [
                       "‚Ä¢ Hechos an√°logos a los planteados.",
                       "‚Ä¢ Norma o art√≠culo citado en el extracto.",
                       "‚Ä¢ Resultado y criterio similar al inter√©s del abogado."
                   ],
                   "resumen": "Relevante para sustentar la demanda en curso."}
                  for c in candidates[:3]]
        return intro, result

# =============================
# Memoria visible
# =============================
if "messages" not in st.session_state:
    st.session_state.messages = []
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).markdown(msg["content"])

# =============================
# Interfaz principal
# =============================
user_input = st.chat_input("Plante√° tu caso (hechos, norma, jurisdicci√≥n, a√±o, etc.)...")
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("user").markdown(user_input)

    # Recupero 10 candidatos
    try:
        candidate_docs = retriever.get_relevant_documents(user_input)
    except Exception:
        candidate_docs = retriever.invoke(user_input)

    if not candidate_docs:
        answer = ("No encontr√© jurisprudencias relevantes en tu base. Prob√° aportar m√°s detalles "
                  "(hechos clave, norma aplicable, jurisdicci√≥n, per√≠odo).")
        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.chat_message("assistant").markdown(answer)
    else:
        # Preparo lista para LLM con uid √∫nico
        candidates = []
        uid_to_doc = {}
        for d in candidate_docs[:10]:
            m = d.metadata or {}
            titulo = m.get("caratula") or m.get("titulo") or "Jurisprudencia"
            trib = m.get("tribunal_principal") or m.get("tribunal") or ""
            fecha = m.get("fecha_sentencia") or ""
            tipo = m.get("tipo_causa") or ""
            descriptor = " ‚Äî ".join([x for x in [titulo, trib, fecha, tipo] if x])
            extracto = (d.page_content or "")[:1600]
            uid = str(uuid.uuid5(uuid.NAMESPACE_DNS, (descriptor + extracto[:200]).strip()))
            candidates.append({"uid": uid, "descriptor": descriptor, "extracto": extracto})
            uid_to_doc[uid] = d

        # El LLM elige 3 y explica
        intro, picked = llm_pick_top3_and_explain(user_input, candidates)
        st.markdown(f"**{intro}**")

        resumen_lineas = []
        for i, item in enumerate(picked, start=1):
            uid = item["uid"]
            d = uid_to_doc.get(uid)
            if not d:
                continue
            meta = d.metadata or {}
            titulo = meta.get("caratula") or meta.get("titulo") or "Jurisprudencia"
            trib = meta.get("tribunal_principal") or meta.get("tribunal") or ""
            fecha = meta.get("fecha_sentencia") or ""
            header = f"**{titulo}**" + (f" ‚Äî {trib}" if trib else "") + (f" ‚Äî {fecha}" if fecha else "")

            st.markdown(f"**{i}. {titulo}**")
            for b in item.get("bullets", []):
                st.markdown(b)
            if item.get("resumen"):
                st.markdown(f"_**Conclusi√≥n:**_ {item['resumen']}")

            with st.expander(header, expanded=(i == 1)):
                render_kv_table(meta)

            resumen_lineas.append(f"{i}. {titulo} ‚Äî {item.get('resumen','')}")

        final_msg = "üß† **Resumen breve:**\n" + "\n\n".join(resumen_lineas)
        st.session_state.messages.append({"role": "assistant", "content": final_msg})
        st.chat_message("assistant").markdown(final_msg)


# =============================
# Nota:
# - Este c√≥digo asume que tu vectorstore FAISS ya existe en 'vectorstore_jurisprudencia'
#   con documentos que contienen en page_content el texto del fallo y, si es posible,
#   metadata como 'caratula', 'tribunal_principal', 'fecha_sentencia', etc.
# - Si quer√©s ajustar el umbral de similitud o filtros por jurisdicci√≥n/a√±o,
#   pod√©s crear el retriever con: vs.as_retriever(search_kwargs={"k": 3, "score_threshold": 0.2})
# =============================
